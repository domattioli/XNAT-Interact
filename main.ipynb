{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Validated XNATLogin --\n",
      "\tUser: dmattioli\n",
      "\tServer: https://rpacs.iibi.uiowa.edu/xnat/\n",
      "\n",
      "-- XNAT Connection --\n",
      "Status:\t\tOpen\n",
      "Signed-in as:\tdmattioli\n",
      "Project:\t<Project Object> GROK_AHRQ_real `AHRQ-GROK Intraoperative Arthroscopy and Trauma Data` (protected) 0 subject  (owner: domattioli) (created on 2024-07-01 08:35:54.707) https://rpacs.iibi.uiowa.edu/xnat//data/projects/GROK_AHRQ_real?format=html\n",
      "\n",
      "SUCCESS! -- Loaded metatables from: C:\\Users\\DMATTI~1\\AppData\\Local\\Temp\\tmpef33ua0_\\MetaTables.json\n",
      "\t...Metatables successfully populated from XNAT data.\n",
      "table_name:  SUBJECTS\n",
      "col in table:  False\n",
      "col in table:  False\n",
      "table_name:  IMAGE_HASHES\n",
      "col in table:  False\n",
      "col in table:  False\n",
      "table_name:  SURGEONS\n",
      "col in table:  True\n",
      "col in table:  True\n",
      "col in table:  True\n",
      "\n",
      "-- MetaTables -- Accessed by: DMATTIOLI\n",
      "   *Last Modified: 2024-07-01T11:22:30.279138-05:00\n",
      "\tTable: REGISTERED_USERS\n",
      "\t1    DMATTIOLI                                         \n",
      "\t2    GTHOMAS                                           \n",
      "\t...\n",
      "\t6    JHILL7                                            \n",
      "\t7    EZWILLIAMS                                        \n",
      "\n",
      "\tTable: ACQUISITION_SITES\n",
      "\t1    UNIVERSITY_OF_IOWA_HOSPITALS_AND_CLINICS          \n",
      "\t2    UNIVERSITY_OF_HOUSTON                             \n",
      "\t3    AMAZON_MECHANICAL_TURK                            \n",
      "\n",
      "\tTable: GROUPS\n",
      "\t1    OPEN_REDUCTION_HIP_FRACTURE–DYNAMIC_HIP_SCREW     \n",
      "\t2    OPEN_REDUCTION_HIP_FRACTURE–CANNULATED_HIP_SCREW  \n",
      "\t...\n",
      "\t14   HIP_ARTHROSCOPY                                   \n",
      "\t15   ANKLE_ARTHROSCOPY                                 \n",
      "\n",
      "\tTable: SUBJECTS\n",
      "\t--Empty--\n",
      "\n",
      "\tTable: IMAGE_HASHES\n",
      "\t--Empty--\n",
      "\n",
      "\tTable: SURGEONS\n",
      "\t1    KARAMM                                            \n",
      "\t2    KOWALSKIH                                         \n",
      "\t3    MBOLLIER                                          \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from typing import Optional as Opt, Tuple, Union, List\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import io\n",
    "import base64\n",
    "import numpy as np\n",
    "import requests\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import pytz\n",
    "\n",
    "import uuid\n",
    "import warnings\n",
    "\n",
    "import pydicom\n",
    "from pydicom.dataset import FileDataset as pydicomFileDataset, FileMetaDataset as pydicomFileMetaDataset\n",
    "from pydicom import Dataset as pydicomDataset, Sequence, dcmread, dcmwrite\n",
    "from pydicom.dataelem import DataElement\n",
    "from pydicom.datadict import dictionary_VR, dictionary_has_tag\n",
    "from pydicom.uid import UID as pydicomUID, generate_uid as generate_pydicomUID\n",
    "\n",
    "\n",
    "from pyxnat import Interface, schema\n",
    "\n",
    "from pathlib import Path, PurePosixPath\n",
    "\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "from src.utilities import LibrarianUtilities, MetaTables, USCentralDateTime, XNATLogin, XNATConnection, ImageHash\n",
    "from src.xnat_experiment_data import *\n",
    "from src.xnat_scan_data import *\n",
    "from src.xnat_resource_data import ORDataIntakeForm\n",
    "\n",
    "\n",
    "login_info, verbose = { 'Username': 'dmattioli', 'Password': 'PooPoopoopoo123$', 'Url': 'https://rpacs.iibi.uiowa.edu/xnat/' }, True\n",
    "validated_login = XNATLogin( login_info, verbose=verbose )\n",
    "connection = XNATConnection( validated_login, stay_connected=True, verbose=verbose )\n",
    "metatables = MetaTables( validated_login, connection, verbose=verbose )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### May need to re-think the experimentdata class(es) inputs now that the resource data can store meta info like acquisition site, group, datetime, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there an OR Data Intake Form available for this procedure?\n",
      "\tEnter \"1\" for Yes or \"2\" for No\n",
      "\n",
      "--- Surgical Procedure Information ---\n",
      "\t(1/29)\tInstitution Name\t--\tPlease Copy-and-Paste from the following list:\t['UNIVERSITY_OF_IOWA_HOSPITALS_AND_CLINICS', 'UNIVERSITY_OF_HOUSTON', 'AMAZON_MECHANICAL_TURK']\n",
      "Invalid entry for Institution Name! Please enter one of the options listed above\n",
      "\n",
      "\t(2/29)\tType of Orthro Procedure\t--\tPlease enter \"1\" for Trauma or \"2\" for Arthro\n",
      "\n",
      "\t(3/29)\tOrtho Procedure Name\t--\tPlease select from the following options:\n",
      "\t\tEnter '1A' for OPEN REDUCTION HIP FRACTURE–DYNAMIC HIP SCREW\n",
      "\t\tEnter '1B' for OPEN REDUCTION HIP FRACTURE–CANNULATED HIP SCREW\n",
      "\t\tEnter '1C' for CLOSED REDUCTION HIP FRACTURE–CANNULATED HIP SCREW\n",
      "\t\tEnter '1D' for PERCUTANEOUS SACROLIAC FIXATION\n",
      "\t\tEnter '1E' for OPEN AND PERCUTANEOUS PILON FRACTURES\n",
      "\t\tEnter '1F' for INTRAMEDULLARY NAIL-CMN\n",
      "\t\tEnter '1G' for INTRAMEDULLARY NAIL-ANTEGRADE FEMORAL\n",
      "\t\tEnter '1H' for INTRAMEDULLARY NAIL-RETROGRADE FEMORAL\n",
      "\t\tEnter '1I' for PEDIATRIC SUPRACONDYLAR HUMERUS FRACTURE REDUCTION AND PINNING\n",
      "\t\tEnter '1J' for SCAPHOID FRACTURE\n",
      "\t\tEnter '2A' for SHOULDER ARTHROSCOPY\n",
      "\t\tEnter '2B' for KNEE ARTHROSCOPY\n",
      "\t\tEnter '2C' for HIP ARTHROSCOPY\n",
      "\t\tEnter '2D' for ANKLE ARTHROSCOPY\n",
      "\t\tEnter '3A' for OTHER\n",
      "\n",
      "\t(6/29)\tSide of Patient's Body\t--\tEnter \"1\" for Right, \"2\" for Left, \"3\" for unknown, or \"4\" for N/A or not relevant.\n",
      "\n",
      "\n",
      "--- Storage Device Information ---\n",
      "\n",
      "\t(27/29)\tWas radiology contacted for this procedure?\n",
      "\tEnter \"1\" for Yes, \"2\" for No, or \"3\" for Unknown.\n",
      " -- SUCCESS -- OR Data Intake Form saved to:\tC:\\Users\\DMATTI~1\\AppData\\Local\\Temp\\tmpef33ua0_\\OR_DATA_INTAKE_FORM.txt\n"
     ]
    }
   ],
   "source": [
    "# d = Path( r'R:\\Anderson_Colaborations\\OR Data Collection\\Temporary-Sensitive_Data\\Case3_6-11_945_Arthro_Shoulder' )\n",
    "# source = 'UNIVERSITY_OF_IOWA_HOSPITALS_AND_CLINICS'\n",
    "# group = 'SHOULDER_ARTHROSCOPY'\n",
    "# dt = USCentralDateTime( '2024-06-11-063932')\n",
    "# zip_dest = r'C:\\Users\\dmattioli\\Projects\\XNAT-Interact\\data\\tmp'\n",
    "\n",
    "intake_form = ORDataIntakeForm( metatables=metatables, login=validated_login )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS! -- Loaded metatables from: C:\\Users\\DMATTI~1\\AppData\\Local\\Temp\\tmp7agjri4g\\MetaTables.json\n",
      "\t...Metatables successfully populated from XNAT data.\n",
      "table_name:  SUBJECTS\n",
      "col in table:  False\n",
      "col in table:  False\n",
      "table_name:  IMAGE_HASHES\n",
      "col in table:  False\n",
      "col in table:  False\n",
      "table_name:  SURGEONS\n",
      "col in table:  True\n",
      "col in table:  True\n",
      "col in table:  True\n",
      "\n",
      "-- MetaTables -- Accessed by: DMATTIOLI\n",
      "   *Last Modified: 2024-07-01T11:22:30.279138-05:00\n",
      "\tTable: REGISTERED_USERS\n",
      "\t1    DMATTIOLI                                         \n",
      "\t2    GTHOMAS                                           \n",
      "\t...\n",
      "\t6    JHILL7                                            \n",
      "\t7    EZWILLIAMS                                        \n",
      "\n",
      "\tTable: ACQUISITION_SITES\n",
      "\t1    UNIVERSITY_OF_IOWA_HOSPITALS_AND_CLINICS          \n",
      "\t2    UNIVERSITY_OF_HOUSTON                             \n",
      "\t3    AMAZON_MECHANICAL_TURK                            \n",
      "\n",
      "\tTable: GROUPS\n",
      "\t1    OPEN_REDUCTION_HIP_FRACTURE–DYNAMIC_HIP_SCREW     \n",
      "\t2    OPEN_REDUCTION_HIP_FRACTURE–CANNULATED_HIP_SCREW  \n",
      "\t...\n",
      "\t14   HIP_ARTHROSCOPY                                   \n",
      "\t15   ANKLE_ARTHROSCOPY                                 \n",
      "\n",
      "\tTable: SUBJECTS\n",
      "\t--Empty--\n",
      "\n",
      "\tTable: IMAGE_HASHES\n",
      "\t--Empty--\n",
      "\n",
      "\tTable: SURGEONS\n",
      "\t1    KARAMM                                            \n",
      "\t2    KOWALSKIH                                         \n",
      "\t3    MBOLLIER                                          \n",
      "\n",
      " -- SourceESVSession --\n",
      "UID:\t2_25_219782268944444994491944262331939733572\n",
      "Acquisition Site:\tUNIVERSITY_OF_IOWA_HOSPITALS_AND_CLINICS\n",
      "Group:\t\t\tKNEE_ARTHROSCOPY\n",
      "Date-Time:\t\t2024-06-11 10:00:00-05:00 US-CST\n",
      "Valid:\t\t\tTrue\n",
      "                                              NEW_FN IS_VALID TYPE\n",
      "0  0001-2_25_160091347024969142733431433648202034079     True  JPG\n",
      "1                                                NaN    False  JPG\n",
      "2  0003-2_25_173591606060892895759458277263268701387     True  JPG\n",
      "3   0004-2_25_54849414944077542718909540287568172987     True  JPG\n",
      "4  0005-2_25_223341595526781064212604438263818038943     True  JPG\n",
      "...\n",
      "                                              NEW_FN IS_VALID TYPE\n",
      "5  0006-2_25_156873294768989318854479381753140180928     True  JPG\n",
      "6   0007-2_25_64718807960761277983051224355714254499     True  JPG\n",
      "7  0008-2_25_265356116143967359176165756486880032624     True  JPG\n",
      "8  0009-2_25_280550677896943951805369943840334734286     True  JPG\n",
      "9   0000-2_25_76642924604781040876335399149422372277     True  MP4\n"
     ]
    }
   ],
   "source": [
    "in_dir = Path( intake_form.relevant_folder ) # type: ignore -- for all of these intake form fields because they are Opt[str] and thus its possible that theyre None.\n",
    "group = intake_form.group\n",
    "acquisition_site = intake_form.acquisition_site\n",
    "procedure_type = intake_form.ortho_procedure_type\n",
    "dt = intake_form.datetime\n",
    "\n",
    "metatables = MetaTables( validated_login, connection, verbose=verbose )\n",
    "source_images = SourceESVSession( pn=in_dir,\n",
    "                                         login=validated_login, xnat_connection=connection, metatables=metatables,\n",
    "                                         acquisition_site=acquisition_site, group=group, datetime=dt, # type: ignore\n",
    "                                         resource_files=[intake_form])\n",
    "print( source_images )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:1094\u001b[0m, in \u001b[0;36mDataFrame.__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1091\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m   1093\u001b[0m repr_params \u001b[38;5;241m=\u001b[39m fmt\u001b[38;5;241m.\u001b[39mget_dataframe_repr_params()\n\u001b[1;32m-> 1094\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrepr_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:1271\u001b[0m, in \u001b[0;36mDataFrame.to_string\u001b[1;34m(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, max_cols, show_dimensions, decimal, line_width, min_rows, max_colwidth, encoding)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_colwidth):\n\u001b[0;32m   1253\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m fmt\u001b[38;5;241m.\u001b[39mDataFrameFormatter(\n\u001b[0;32m   1254\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1255\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1269\u001b[0m         decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   1270\u001b[0m     )\n\u001b[1;32m-> 1271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mline_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\io\\formats\\format.py:1134\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_string\u001b[1;34m(self, buf, encoding, line_width)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringFormatter\n\u001b[0;32m   1133\u001b[0m string_formatter \u001b[38;5;241m=\u001b[39m StringFormatter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt, line_width\u001b[38;5;241m=\u001b[39mline_width)\n\u001b[1;32m-> 1134\u001b[0m string \u001b[38;5;241m=\u001b[39m \u001b[43mstring_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m save_to_buffer(string, buf\u001b[38;5;241m=\u001b[39mbuf, encoding\u001b[38;5;241m=\u001b[39mencoding)\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\io\\formats\\string.py:30\u001b[0m, in \u001b[0;36mStringFormatter.to_string\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_string\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m---> 30\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_string_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt\u001b[38;5;241m.\u001b[39mshould_show_dimensions:\n\u001b[0;32m     32\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([text, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt\u001b[38;5;241m.\u001b[39mdimensions_info])\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\io\\formats\\string.py:45\u001b[0m, in \u001b[0;36mStringFormatter._get_string_representation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_empty_info_line\n\u001b[1;32m---> 45\u001b[0m strcols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_strcols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# no need to wrap around just print the whole frame\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj\u001b[38;5;241m.\u001b[39madjoin(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39mstrcols)\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\io\\formats\\string.py:36\u001b[0m, in \u001b[0;36mStringFormatter._get_strcols\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_strcols\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[1;32m---> 36\u001b[0m     strcols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strcols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt\u001b[38;5;241m.\u001b[39mis_truncated:\n\u001b[0;32m     38\u001b[0m         strcols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_dot_separators(strcols)\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\io\\formats\\format.py:615\u001b[0m, in \u001b[0;36mDataFrameFormatter.get_strcols\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_strcols\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[0;32m    612\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;124;03m    Render a DataFrame to a list of columns (as lists of strings).\u001b[39;00m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m     strcols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_strcols_without_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex:\n\u001b[0;32m    618\u001b[0m         str_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_formatted_index(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtr_frame)\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\io\\formats\\format.py:881\u001b[0m, in \u001b[0;36mDataFrameFormatter._get_strcols_without_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    877\u001b[0m cheader \u001b[38;5;241m=\u001b[39m str_columns[i]\n\u001b[0;32m    878\u001b[0m header_colwidth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_space\u001b[38;5;241m.\u001b[39mget(c, \u001b[38;5;241m0\u001b[39m)), \u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj\u001b[38;5;241m.\u001b[39mlen(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m cheader)\n\u001b[0;32m    880\u001b[0m )\n\u001b[1;32m--> 881\u001b[0m fmt_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_col\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m fmt_values \u001b[38;5;241m=\u001b[39m _make_fixed_width(\n\u001b[0;32m    883\u001b[0m     fmt_values, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjustify, minimum\u001b[38;5;241m=\u001b[39mheader_colwidth, adj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj\n\u001b[0;32m    884\u001b[0m )\n\u001b[0;32m    886\u001b[0m max_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj\u001b[38;5;241m.\u001b[39mlen(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m fmt_values), header_colwidth)\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\io\\formats\\format.py:895\u001b[0m, in \u001b[0;36mDataFrameFormatter.format_col\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    893\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtr_frame\n\u001b[0;32m    894\u001b[0m formatter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_formatter(i)\n\u001b[1;32m--> 895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformat_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleading_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\io\\formats\\format.py:1330\u001b[0m, in \u001b[0;36mformat_array\u001b[1;34m(values, formatter, float_format, na_rep, digits, space, justify, decimal, leading_space, quoting, fallback_formatter)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     digits \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.precision\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1316\u001b[0m fmt_obj \u001b[38;5;241m=\u001b[39m fmt_klass(\n\u001b[0;32m   1317\u001b[0m     values,\n\u001b[0;32m   1318\u001b[0m     digits\u001b[38;5;241m=\u001b[39mdigits,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     fallback_formatter\u001b[38;5;241m=\u001b[39mfallback_formatter,\n\u001b[0;32m   1328\u001b[0m )\n\u001b[1;32m-> 1330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmt_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\io\\formats\\format.py:1363\u001b[0m, in \u001b[0;36mGenericArrayFormatter.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_result\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m-> 1363\u001b[0m     fmt_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_strings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _make_fixed_width(fmt_values, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjustify)\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\io\\formats\\format.py:1430\u001b[0m, in \u001b[0;36mGenericArrayFormatter._format_strings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(vals):\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m is_float_type[i] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformatter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m leading_space:\n\u001b[1;32m-> 1430\u001b[0m         fmt_values\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_format(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1431\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_float_type[i]:\n\u001b[0;32m   1432\u001b[0m         fmt_values\u001b[38;5;241m.\u001b[39mappend(float_format(v))\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\io\\formats\\format.py:1410\u001b[0m, in \u001b[0;36mGenericArrayFormatter._format_strings.<locals>._format\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mrepr\u001b[39m(x)\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1409\u001b[0m     \u001b[38;5;66;03m# object dtype\u001b[39;00m\n\u001b[1;32m-> 1410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\io\\formats\\printing.py:232\u001b[0m, in \u001b[0;36mpprint_thing\u001b[1;34m(thing, _nest_lvl, escape_chars, default_escapes, quote_strings, max_seq_items)\u001b[0m\n\u001b[0;32m    230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mas_escaped_string(thing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 232\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mas_escaped_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\.venv\\lib\\site-packages\\pandas\\io\\formats\\printing.py:208\u001b[0m, in \u001b[0;36mpprint_thing.<locals>.as_escaped_string\u001b[1;34m(thing, escape_chars)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     escape_chars \u001b[38;5;241m=\u001b[39m escape_chars \u001b[38;5;129;01mor\u001b[39;00m ()\n\u001b[1;32m--> 208\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mthing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m escape_chars:\n\u001b[0;32m    210\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreplace(c, translate[c])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "print( source_images.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSUCCESS! --- Added \"2_25_219782268944444994491944262331939733572\" to table \"SUBJECTS\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msource_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# source_images.write_publish_catalog_subroutine( schema_prefix_str='esv', verbose=True )\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\src\\xnat_experiment_data.py:480\u001b[0m, in \u001b[0;36mSourceESVSession.write\u001b[1;34m(self, zip_dest, verbose)\u001b[0m\n\u001b[0;32m    478\u001b[0m     img_ffn \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin( tmp_dir, \u001b[38;5;28mstr\u001b[39m( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_FN\u001b[39m\u001b[38;5;124m'\u001b[39m] ) )\n\u001b[0;32m    479\u001b[0m     dcmwrite( img_ffn, file_obj_rep\u001b[38;5;241m.\u001b[39mmetadata ) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m--> 480\u001b[0m     img_info \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBJECT\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetatables\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_uid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSUBJECTS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muid\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINSTANCE_NUM\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_FN\u001b[39m\u001b[38;5;124m'\u001b[39m] }\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetatables\u001b[38;5;241m.\u001b[39madd_new_item( table_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIMAGE_HASHES\u001b[39m\u001b[38;5;124m'\u001b[39m, item_name\u001b[38;5;241m=\u001b[39mfile_obj_rep\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mhash_str, extra_columns_values\u001b[38;5;241m=\u001b[39mimg_info, verbose\u001b[38;5;241m=\u001b[39mverbose ) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m( file_obj_rep, ArthroVideo ): \u001b[38;5;66;03m# Don't need to add this to metatables because the diagnostic images (frames from the video) should suffice.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dmattioli\\Projects\\XNAT-Interact\\src\\utilities.py:607\u001b[0m, in \u001b[0;36mMetaTables.get_uid\u001b[1;34m(self, table_name, item_name)\u001b[0m\n\u001b[0;32m    605\u001b[0m table_name, item_name \u001b[38;5;241m=\u001b[39m table_name\u001b[38;5;241m.\u001b[39mupper(), item_name\u001b[38;5;241m.\u001b[39mupper()\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_exists( table_name, item_name ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist in table \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m( \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtables\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtables\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNAME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mitem_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m )\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "source_images.write( verbose=True )\n",
    "# source_images.write_publish_catalog_subroutine( schema_prefix_str='esv', verbose=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete all subjects in server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://rpacs.iibi.uiowa.edu/xnat/ dmattioli PooPoopoopoo123$\n",
      "['202306334', 'AF-OTA', 'domSandBox', 'ExampleProject', 'IOWA_UIA', 'Mouse_Atlas', 'OBL_GROK_SST', 'PAO-JCS', 'SURGSIM', 'TestProject', 'TestProjectID']\n",
      "['RPACS_S52872', 'RPACS_S52890', 'RPACS_S54228', 'RPACS_S54229', 'RPACS_S54230', 'RPACS_S54231', 'RPACS_S54233', 'RPACS_S54234', 'RPACS_S54235']\n",
      "Failed to delete subject:  RPACS_S52872\n",
      "Failed to delete subject:  RPACS_S52890\n"
     ]
    }
   ],
   "source": [
    "# %run src/delete_contents_of_server.py --server {login_info['Url']} --username {login_info['Username']} --password {login_info['Password']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTurkSemanticSegmentation( ScanFile ):\n",
    "    ''' # Example usage:\n",
    "    print( MTurkSemanticSegmentation( pd.read_csv( r'...\\\\data\\\\examples\\\\MTurkSemanticSegmentation_Example_File.csv' ) ) )\n",
    "    '''\n",
    "    def __init__( self, assignment: pd.Series, metatables: MetaTables ): #to-do: allow for different input types eg batch file data or pulled-from-xnat data\n",
    "        super().__init__( metatables )  # Call the __init__ method of the base class\n",
    "        self._validate_input( assignment )\n",
    "        self._read_image()\n",
    "        self._extract_target_object_info() #to-do\n",
    "        self._extract_date_and_time()\n",
    "        # self._extract_uid_info()\n",
    "        self._extract_pngImageData()\n",
    "        self._check_data_validity()\n",
    "\n",
    "    @property\n",
    "    def bw( self ) -> np.ndarray:   return self._bw\n",
    "    \n",
    "    def _validate_input( self, assignment: pd.Series ):\n",
    "        assert len( set(self.mturk_batch_col_names) - set(assignment.columns) ) == 0, f\"Missing required columns: {set(self.mturk_batch_col_names) - set(assignment.columns)}\"\n",
    "        self._metadata = assignment.loc[0]\n",
    "        img_s3_url = assignment.loc[0,'Input.image_url']\n",
    "        assert self.is_s3_url( img_s3_url ), f'Input.image_url column of inputted data series (row) must be an s3 url: {img_s3_url}'\n",
    "        self._ffn = self.metadata['Input.image_url']\n",
    "        self._bw, self._acquisition_site = self.image.dummy_image(), 'AMAZON_MECHANICAL_TURK' #to-do: this is copy-pasted from the MetaTables, need to figure out how to query it.\n",
    "\n",
    "    def _check_data_validity( self ): # need to check that the pnd image *does* exist in metatables\n",
    "        self._is_valid = self.image.in_img_hash_metatable and not self.is_similar_to_template_image()\n",
    "    \n",
    "    def _extract_target_object_info( self ):\n",
    "        pass\n",
    "\n",
    "    def _extract_date_and_time( self ):\n",
    "        self._datetime = USCentralDateTime( self.metadata.loc['SubmitTime'] )\n",
    "\n",
    "    def _extract_pngImageData( self ):\n",
    "        pngImageData_index = [i for i, c in enumerate( self.metadata.index.to_list() ) if '.pngImageData' in c]\n",
    "        self._bw = self.convert_base64_to_np_array( self.metadata.iloc[pngImageData_index[0]] )\n",
    "\n",
    "     \n",
    "    def __str__( self ):\n",
    "        return f'{self.__class__.__name__}:\\t{self.ffn}\\nIs Valid:\\t{self.is_valid}\\nAcquisition Site: {self.acquisition_site}\\nGroup:\\t\\t{self.group}\\nDatetime:\\t{self.datetime}\\nUID Info: {self.uid_info}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_acceptable_keywords( metatables: MetaTables ):\n",
    "    # walk through the 'GROUPS' and 'ACQUISITION_SITES' tables and write the Name for each item as a row in a text file that mimics a compact dataframe\n",
    "    target_tables = ['GROUPS','ACQUISITION_SITES']\n",
    "    out_ffn = os.path.join( metatables.doc_dir, 'acceptable_upload_keyword_inputs.txt')\n",
    "    text_to_write = f'Acceptable Inputs -- Uploading a New Performance\\n{\"---\"*20}\\n\\n'\n",
    "    for t_name in target_tables:\n",
    "        table_items_list = metatables.list_of_all_items_in_table( table_name=t_name )\n",
    "        text_to_write += f'Key: {t_name}\\n'\n",
    "        for item in table_items_list:\n",
    "            text_to_write += f'\\t- {item}\\n'\n",
    "        text_to_write += '\\n'\n",
    "        \n",
    "    with open( out_ffn, 'w' ) as f:\n",
    "        f.write( text_to_write )\n",
    "    # with open( f'{t_name}.txt', 'w' ) as f:\n",
    "    #     f.write( f'{t_name}\\n' )\n",
    "    #     f.write( f'NAME\\n' )\n",
    "\n",
    "write_acceptable_keywords( metatables )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OtherDicomSession():\n",
    "    def __init__( self, batch_ffn: str, login: XNATLogin, xnat_connection: XNATConnection, metatables: MetaTables, object: str, print_out: bool=False ):\n",
    "        self._batch_ffn = batch_ffn\n",
    "        self._login = login\n",
    "        self._xnat_connection = xnat_connection\n",
    "        self._metatables = metatables\n",
    "        assert self._metatables.item_exists( table_name='Acquisition_sites', item_name='AMAZON_MECHANICAL_TURK' )\n",
    "        assert self._metatables.table_exists( 'Segmentation_Objects' )\n",
    "        assert self._metatables.item_exists( table_name='Segmentation_Objects', item_name=object )\n",
    "        self._acquisition_site, self._object = 'AMAZON_MECHANICAL_TURK', object\n",
    "\n",
    "        \n",
    "        # metatables.add_new_item( table_name='MTURK_BATCH_IDS', item_name='Segmentation', extra_columns_values={'task':'Segmentation'} )\n",
    "\n",
    "\n",
    "        # attributes that metatables will eventually need to store -- to-do:\n",
    "        self._object, self._object_type = object, 'BONE'\n",
    "        self._object_code, self._object_type_code, self._CodingSchemeDesignator = 'T-12760', 'T-32000', 'SRT' # Code for 'Femur', 'Bone', according to copilot gpt\n",
    "        self._SegmentAlgorithmType, self._SegmentAlgorithmName, self._SegmentationType = 'MANUAL', 'MTURK', 'BINARY'\n",
    "        \n",
    "        self._mediastoragesopclassuid, self._transfersyntaxuid = pydicomUID('1.2.840.10008.5.1.1.4'), pydicomUID('1.2.840.10008.1.2') # Basic Grayscale Image Box SOP Class, Implicit VR Little Endian\n",
    "        self._print_out = print_out    \n",
    "\n",
    "        # Create a new df with the number of rows equal to the number of groups. create a column for the respective Input.image_url\n",
    "        self._raw_data = pd.read_csv( self._batch_ffn )\n",
    "        self._datetime = USCentralDateTime( self._raw_data.loc[0, 'ApprovalTime'] )\n",
    "        icol = self._get_pngImageData_col()\n",
    "        self._raw_data['BinaryImages'] = [self.convert_base64_to_np_array( row[icol] ) for i, row in self._raw_data.iterrows()]\n",
    "        self._grouped_data = self._raw_data.groupby( 'Input.image_url' )\n",
    "        self._df = pd.DataFrame( index=range( len( self._grouped_data ) ), columns=['SUBJECT_XNAT_UID',\n",
    "                                                                                    'image_hashes_mt_uid', 'subject_mt_uid',\n",
    "                                                                                    'FN', 'IS_VALID', 'IMAGE_HASHES', 'BWS' 'DCMDATA', 'UID_INFO', 'FFN'] )\n",
    "        \n",
    "        # for each row of self._df compute the ImageHash for the s3url in that row's Image\n",
    "        self._df['FFN'] = [group for group, data in self._grouped_data]\n",
    "        self._df['FN'] = [s3url.split('/')[-1] for s3url in self._df['FFN']]\n",
    "        self._df['IMAGE_HASHES'] = [self._read_image( s3url ) for s3url in self._df['FFN']]\n",
    "        self._df['UID_INFO'] = self._grouped_data.apply(lambda g: {'HITIDS': g['HITId'].tolist(), \n",
    "                                                            'ASSIGNMENTIDS': g['AssignmentId'].tolist(), \n",
    "                                                            'WORKERIDS': g['WorkerId'].tolist()}).reset_index(drop=True)\n",
    "        \n",
    "        # Store a list of the binary images in the BWS col\n",
    "        self._df['BWS'] = [data['BinaryImages'].to_list() for group, data in self._grouped_data]\n",
    "\n",
    "        # given that hash_str is a property of each item in the objects stored in each row of self._df['ImageHashes'], apply self._metatables.item_exists( table_name='IMAGE_HASHES', item_name=hash_str) via list comprehension\n",
    "        self._df['IS_VALID'] = [self._metatables.item_exists(table_name='IMAGE_HASHES', item_name=item.hash_str) for item in self._df['IMAGE_HASHES']]\n",
    "\n",
    "        # Create a dicom file for each row such that the semantic segmentation data is stacked\n",
    "        self._create_DCMDATA()\n",
    "\n",
    "        # create a list of dataframes such that each dataframe groups together the self._df rows that correspond to images belonging to the same subject.\n",
    "        self._group_rows_by_subject()\n",
    "        \n",
    "        \n",
    "    def _get_table( self, table_name: str ) -> pd.DataFrame: #to-do: move this to metatables class definition.\n",
    "        assert self._metatables.table_exists( table_name ), f'Table {table_name} does not exist in metatables'\n",
    "        return self._metatables.tables[table_name]\n",
    "\n",
    "    # def _get_item( self, table_name: str, item_name: str ) -> pd.Series: #to-do: move this to metatables class definition\n",
    "    #     # table name represents the table in self._metatables.tables that we want. item_name is the row of that table that we want. return the row as a pd.series\n",
    "    #     return self._get_table(table_name).loc[item_name]\n",
    "\n",
    "\n",
    "    def _read_image( self, s3url: str ) -> ImageHash:\n",
    "        response = requests.get( s3url, stream=True )\n",
    "        response.raw.decode_content = True\n",
    "        arr = np.asarray( bytearray( response.raw.read() ), dtype=np.uint8 )\n",
    "        return ImageHash( metatables=self._metatables, img=cv2.imdecode( arr, cv2.IMREAD_GRAYSCALE ) ) # img = Image.open( response.raw )\n",
    "\n",
    "    # write a method that returns the column name containing the substring .pngImageData\n",
    "    def _get_pngImageData_col( self ) -> str:\n",
    "        return [c for c in self._raw_data.columns if '.pngImageData' in c][0]\n",
    "\n",
    "    def convert_base64_to_np_array( self, b64_str: str ) -> np.ndarray:\n",
    "        return cv2.imdecode( np.frombuffer( base64.b64decode( b64_str ), np.uint8 ), cv2.IMREAD_GRAYSCALE )\n",
    "\n",
    "    def _derive_subject_instance_num( self, subject_xnat_uid: str, hash_str: str, image_hashes_mt_uid: str ) -> str: # filename that we need to mimic\n",
    "            \n",
    "        pass\n",
    "\n",
    "    def _create_DCMDATA( self ):\n",
    "        hash_table, subject_table, registered_user_table = self._get_table( 'IMAGE_HASHES' ), self._get_table( 'SUBJECTS' ), self._get_table( 'REGISTERED_USERS' )\n",
    "        user_mt_uid = registered_user_table.loc[registered_user_table['NAME'] == self._login.validated_username.upper(), 'UID'].values[0]\n",
    "        for i, row in self._df.iterrows():\n",
    "            if not row['IS_VALID']:\n",
    "                continue\n",
    "            image_hashes_mt_uid = row['IMAGE_HASHES'].hash_str.upper()\n",
    "            subject_mt_uid = hash_table.loc[hash_table['NAME'] == image_hashes_mt_uid, 'SUBJECT'].values[0] # type: ignore\n",
    "            self._df.loc[i,'SUBJECT_XNAT_UID'] = subject_table.loc[subject_table['UID'] == subject_mt_uid, 'NAME'].values[0] # type: ignore\n",
    "            self._df.loc[i,'image_hashes_mt_uid'] = image_hashes_mt_uid\n",
    "            self._df.loc[i,'subject_mt_uid'] = subject_mt_uid\n",
    "            dcm = self._create_dicom( subject_name=self._df.loc[i,'SUBJECT_XNAT_UID'], user_uid=user_mt_uid, bws=row['BWS'], uids=row['UID_INFO'] )\n",
    "            self._df.loc[i, 'DCMDATA'] = [dcm]\n",
    "\n",
    "    def _create_dicom( self, subject_name: str, user_uid: str, bws: list, uids: dict ) -> pydicomDataset:\n",
    "        # Create a dicom file to represent the segmentations for the referenced dicom file\n",
    "        file_meta = pydicomFileMetaDataset()\n",
    "        file_meta.MediaStorageSOPClassUID = self._mediastoragesopclassuid \n",
    "        # file_meta.MediaStorageSOPInstanceUID = pydicomUID.generate_uid()\n",
    "        # file_meta.ImplementationClassUID = pydicomUID.generate_uid()\n",
    "        file_meta.TransferSyntaxUID = self._transfersyntaxuid\n",
    "        \n",
    "        dcm = pydicom.Dataset()\n",
    "        dcm.StudyInstanceUID = pydicomUID( subject_name ) # to-do: should be pydicom compliant already, will need to come back to this with a revised metatable\n",
    "        HIT_id = str( uids['HITIDS'][0] )\n",
    "        # dcm.UID = pydicomUID( HIT_id ) # HIT Id -- to-do: will need to redo this table to include pydicom compliant uids\n",
    "        dcm.file_meta = file_meta\n",
    "        # dcm.ReferencedSOPInstanceUID = original_dcm.SOPInstanceUID\n",
    "        dcm.InstanceCreationDate, dcm.InstanceCreationTime = self._datetime.date, self._datetime.time\n",
    "        dcm.InstanceCreatorUID = generate_pydicomUID() # to-do: will need to redo this table to include pydicom compliant uids\n",
    "        # dcm.InstanceCreatorUID = user_uid # to-do: will need to redo this table to include pydicom compliant uids\n",
    "        dcm.ImageType = ['DERIVED', 'PRIMARY', 'SEGMENTATION']\n",
    "        dcm.Modality = 'KO' # Key Object Selection\n",
    "        dcm.LargestImagePixelValue, dcm.SmallestImagePixelValue = np.uint( 1 ), np.uint( 0 )\n",
    "        dcm.SeriesDescription = 'Instructions Refinement - Iteration N'\n",
    "        dcm.SegmentSequence = self._create_segment_sequence( uids, bws )\n",
    "        return dcm\n",
    "\n",
    "    def _create_segment_sequence( self, uids: dict, bws: list ) -> Sequence:\n",
    "        segment_sequence = Sequence()\n",
    "        for idx, bw in enumerate( bws ):\n",
    "            seg = Dataset()\n",
    "            seg.SegmentNumber = idx # Worker ID here\n",
    "            seg.OperatorsName = str( uids['WORKERIDS'][idx] ) # Worker ID here\n",
    "            seg.add_new( (0x0019, 0x10a0), 'LO', \"Operators' Name : WorkerID\" )\n",
    "            seg.SegmentLabel = str( uids['ASSIGNMENTIDS'][idx] ) # To:do: Assignment ID here to denote the unique submission of the worker for this HIT\n",
    "            seg.SegmentAlgorithmType, seg.SegmentAlgorithmName, seg.SegmentationType = self._SegmentAlgorithmType, self._SegmentAlgorithmName, self._SegmentationType\n",
    "            \n",
    "            # Create a CodeSequence for the SegmentedPropertyCategoryCodeSequence attribute\n",
    "            code_sequence = Dataset()\n",
    "            code_sequence.CodeValue, code_sequence.CodingSchemeDesignator, code_sequence.CodeMeaning = self._object_type_code, self._CodingSchemeDesignator, self._object_type\n",
    "            seg.SegmentedPropertyCategoryCodeSequence = Sequence( [code_sequence] )\n",
    "            \n",
    "            # Create a CodeSequence for the SegmentedPropertyTypeCodeSequence attribute -- same as above\n",
    "            seg.SegmentedPropertyTypeCodeSequence = Sequence( [code_sequence.copy()] )\n",
    "            \n",
    "            # seg.SegmentDescription = 'Instructions Refinement - Iteration N'\n",
    "            seg.PixelData, seg.Rows, seg.Columns = bw.tobytes(), bw.shape[0], bw.shape[1]\n",
    "            segment_sequence.append( seg )\n",
    "        #     self._metatables.add_new_item( table_name='MTURK_WORKER_IDS', item_name=seg.SegmentNumber, extra_columns_values={'MTURK_HIT_ID': HIT_id } )\n",
    "        #     self._metatables.add_new_item( table_name='MTURK_ASSIGNMENT_IDS', item_name=seg.SegmentLabel, extra_columns_values={'MTURK_HIT_ID': HIT_id, 'MTURK_WORKER_ID': seg.SegmentNumber } )\n",
    "        # self._metatables.add_new_item( table_name='MTURK_HIT_IDS', item_name=HIT_id )\n",
    "        return segment_sequence\n",
    "    \n",
    "    def _group_rows_by_subject( self ):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def write( self, idcm: int, zip_dest: Opt[str] = None, print_out: Opt[bool] = False ) -> str: #write individiual dicom files to a zipped folder\n",
    "        \n",
    "        if not self._df.loc[idcm, 'IS_VALID']:\n",
    "            # if print_out:\n",
    "            print( f'***Session is invalid; could be for several reasons. try evaluating whether all of the image hash_strings already exist in the matatable.' )\n",
    "        pass\n",
    "\n",
    "    def catalog_new_data( self ):\n",
    "        self._metatables.save( print_out=print_out )\n",
    "        pass\n",
    "\n",
    "batch_ffn = r'C:\\Users\\dmattioli\\Projects\\XNAT\\data\\examples\\MTurkSemanticSegmentation_Example_2.csv'\n",
    "poo = OtherDicomSession( batch_ffn, validated_login, connection, metatables, object='Humerus' )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
